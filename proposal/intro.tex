% !TEX root ../proposal.tex

Large-scale empirisicm, enabled by Internet-wide scanning, provides missing
insight into the security of cryptography used on the Internet. 

% What insight is "missing"? What are the other methods?

We gain additional insight into cryptography from large-scale empiricism.

The Internet is a large, distributed system with a diverse set of clients and
servers~\cite{something}. Compatibility with legacy clients remains a top priority 
for many operators~\cite{something} and protocol designers~\cite{something}.

% High-level questions that empiricism helps with. (TLS 1.3 compatibility woes?)
%
% List of insights that help with this.

We can use that insight to improve the overall security of the Internet, today.

We can use that insight to better inform the design of the Internet in the future.

The latest version of TLS 1.3~\cite{rfc8446} was drafted over the course of \TK years, with countermeasures
in place for both known cryptographic vulnerabilites in earlier version of TLS, as well as with updated negotation and parameter selection processes, designed to prevent deployment failures that had traditionally been considered outside of the scope of standards.

We can use it alongside analysis of individual components. (With our power combined!)

Using large-scale empiriscism requires solving engineering challenges.

\section{Large-scale Empiricism}

% Some people study cryptograpy usages in individual programs~\cite{most-dangerous-code-2012}.
% 
% API design helps.
% 
% But ultimately, what is happening? Are we impacting the security on the web as a whole?
% 
% But what about ecosystems?
% 
% Study usage across ecosystems.
% 
% Usage is configuration.
% 
% Design experiments to glean information into configuration.
% 
% Talk about configuration of the ecosystem beyond just configuration of hosts (cross-protocol correlation).

Security research often involves searching for new classes of
vulnerabilites~\cite{something}, or identifying vulnerabilites within
existing systems~\cite{something}. Other research has concerned identifying
misuse of security-critical APIs~\cite{gutmann-lessons}, including systematic
misuse among large swaths of library code
users~\cite{most-dangerous-code-2012}. While improving API design and
secure-by-default programming models certainly improve the security behavior
surrounding network communication for many programs, it does not provide
insight into the security behavior of Internet ecosystems themselves.

Large-scale empiricism enables us to understand the security behavior
ecosystems, rather than \TK. To understand the behavior of users of cryptographic applications, 

\subsection{Cryptography in the TLS Ecosystem}

Configuration of web servers.

Logjam.

Diffie-Hellman. Subgroup.

RFC 5114

\subsection{Unexpected Interactions in Cryptography at Scale}

Beyond examining individual protocols at the global perspective, new issues can
be identified by looking across multiple similar protocols. Although it is
tempting to consider the security of any given system in isolation, complex
interactions between systems necessarily impacts security.

At the most-basic level, cross-protocol key-reuse links the security of any two
protocols together in key-compromise scenarios. When the same server private
key is used for both a mail server and a web server, compromising the often
less-secured mail server effectively compromises the web
server~\cite{mail-2015}.

Looking past simply key reuse, name reuse across protocols utilizing TLS opens
additional attack vectors. Any service with a certificate chaining to a
publicly trusted root that shares a Common Name or Subject Alternative Name
with a web server, or that covers the web address under a wildcard name, can be
used to impersonate the web server if the key is compromised.

Furthermore, specific vulnerabilites in the TLS protocol and implementations
can be utilized in a cross-protocol context to attack users of a web service
using an unpatched ``forgotten-about'' server, such as a mail server, without
even explicitly compromising the private key of the service. The best example
of this is the DROWN vulnerability~\cite{drown-2016}, in which the mere
existence of an SSLv2 host that shared a key with a TLS host enabled decryption
of otherwise secure TLS connections using modern cryptography.

\paragraph{Cross-protocol interactions between TLS and SSLv2}

SSLv2

DROWN

Generalize DROWN to cross-protocol key reusage

\paragraph{Export Cryptography}
Don't weaken cryptography.

Takeaways from Black Hat talk.

\section{Engineering Challenges}

To do science, we have to collect data.

To collect the data, we have to build things.

Determining what to build and how to build is also difficult.

Engineering is very closely related to methodology, which is where the science is.

\subsection{Speed}

Assume we're using scanning.

TLS-Attacker is slow.

Performance matters, especially once you start cross-correlating.

Discovery and collection separate. (ZMap vs ZGrab)

\subsection{Data Processing}

Beyond collecting data, you actually have to process it.

Straightforward for one-off studies.

What if you want longitudinal data?

Take-away This all requires work.
